==============================================================================
  AI TMR Assistant — 모델 성능 비교 리포트
==============================================================================
  생성: 2026-02-09 09:37 | 턴: 106 × 5모델 | Judge: openai/gpt-4o
  commit: a3c3da8 | run_id: 20260208_050714
  config:   seed=?  temp=?  tool_choice=?
  config:   judge: seed=?  temp=?  max_tokens=?

  용어 정의:
    @T7 (실무 구간) = Turn 1~7까지의 누적 성능. TMR 영업콜의
    실무 턴 수(청약 ~7턴, 보류 ~5턴)에 대응하는 운영 기준선.
    T7 이후(T10~T19)는 스트레스 테스트 구간으로 내구도 진단용.

==============================================================================
  실무 기준(7턴) 1위: qwen3-14b  Performance 82%
  병목: Arg Acc 80% / No-Call 33%  |  NL 1위: qwen3-14b (50%)
  → 1모델 권장: qwen3-14b (Agent+답변 겸용)
==============================================================================
  ※ 본 벤치마크는 최대 19턴 스트레스 테스트를 포함합니다.
    실무 TMR 콜은 보통 5~7턴이므로, @T7 누적을 실무 성능으로 봅니다.
    T7 이후는 내구도 진단용이며, 운영 목표 수치가 아닙니다.

==============================================================================
  1. 모델별 성적표
==============================================================================

  Tool Acc = tool 호출 정답률 (94턴)
  Arg Acc  = 인자 정확도 (tool name 정답일 때만)
  FC Judge = 행동 판단 정확도 (전체 106턴)
  NL Qual  = 자연어 답변 품질 (LLM Judge, 텍스트 있는 턴만)
  Perf     = 종합 (tool턴: (Tool+Arg+FC)/3, no-call턴: FC)
  ※ 실무 = ~T7 누적 | 전체 = ~T19 누적 (스트레스 포함)

  모델                              Tool     Arg      FC      NL    │ 실무     전체    Gap
  ──────────────────────────── ─────── ─────── ─────── ─────── ─────── ────── ──────
  llama-3.3-70b-instruct        85.6%  36.5%  84.4%   N/A  │  68%   67%   +2%p
  mistral-small-3.2-24b-ins     42.6%  31.1%  66.7%    28% │  44%   51%   -7%p
  qwen3-32b                     77.1%  56.3%  85.1%    43% │  76%   72%   +3%p
  qwen3-14b                     83.0%  59.2%  87.4%    50% │  82%   75%   +6%p ◀ Agent1위,NL1위
  qwen3-next-80b-a3b-instru     78.2%  58.5%  86.9%    24% │  77%   76%   +0%p

  ※ 전체 Perf 1위는 qwen3-next-80b-a3b-instru(실무 77% → 전체 76%)이나,
    qwen3-14b(실무 82% → 전체 75%)가 85%+ ~T3까지 유지 → Agent 1위.

  [1위 모델 실무 구간(@T7) 세부]
    대상: qwen3-14b | 실무 턴: 42턴 (tool_call 36 + no_call 6)
    Tool Acc    93%  ← 이미 우수
    Arg Acc     80%  ← 🔴 병목
    FC Judge    96%  ← 이미 우수
    No-Call     33%  ← 🔴 병목
    ─────────────────────
    Perf        82%
    → 개선 우선순위: No-Call(33%) > Arg Acc(80%)

==============================================================================
  2. 능력 해부 — Single / Parallel / No-Call
==============================================================================

  [Single — tool 1개 호출 (82턴)]
    모델                             tool 정답      인자 정답
    ──────────────────────────── ───────── ──────────
    llama-3.3-70b-instruct            91%       39%
    mistral-small-3.2-24b-ins         43%       33%
    qwen3-32b                         82%       62%
    qwen3-14b                         88%       64%
    qwen3-next-80b-a3b-instru         82%       62%

  [Parallel — tool 2개 동시 호출 (12턴)]
    모델                             tool 정답      인자 정답     2개 인식
    ──────────────────────────── ───────── ────────── ─────────
    llama-3.3-70b-instruct            46%       21%       0%
    mistral-small-3.2-24b-ins         42%       19%      50%
    qwen3-32b                         46%       20%      17%
    qwen3-14b                         50%       27%      50%
    qwen3-next-80b-a3b-instru         54%       38%      17%
    → 최고 17%. 실서비스에서는 1개씩 분리 호출 필요.

  [No-Call — tool 안 불러야 정답 (12턴)]
    모델                                미호출 정답      질문      거부       누락 전부 질문       텍스트 품질
    ──────────────────────────── ─────────── ─────── ─────── ────────────── ────────────
    llama-3.3-70b-instruct               0%     0%     0%            0%         N/A
    mistral-small-3.2-24b-ins           92%    83%   100%           36%         20%
    qwen3-32b                           42%    17%    67%            6%         40%
    qwen3-14b                           33%     0%    67%            0%         75%
    qwen3-next-80b-a3b-instru           83%    67%   100%           11%         30%
    ⚠ llama-3.3-70b-instruct, qwen3-32b, qwen3-14b: 정보 부족해도 tool 호출 → 위험

  [No-Call vs Tool 호출 — trade-off 분석]
    모델                            Tool Acc    NC 정답             성향
    ──────────────────────────── ───────── ──────── ──────────────
    llama-3.3-70b-instruct            86%      0%        tool 과잉
    mistral-small-3.2-24b-ins         43%     92%        tool 부족
    qwen3-32b                         77%     42%        tool 과잉
    qwen3-14b                         83%     33%        tool 과잉
    qwen3-next-80b-a3b-instru         78%     83%             균형
    → tool 과잉 모델은 프롬프트로 개선 가능 (few-shot: '정보 부족 시 tool 대신 질문' 예시 추가)

==============================================================================
  3. 성능 곡선 — 몇 턴까지 85%를 유지하는가?
==============================================================================

  시나리오를 T3~T19 지점에서 잘라 누적 평균을 계산한다.
  🟢 90%+ | 🔵 85%+ | 🟡 75%+ | 🔴 <75%  (85% = 절대 임계선)

  [3a] Performance 종합
    모델                                 ~T3       ~T5       ~T7      ~T10      ~T13      ~T15      ~T17      ~T19
    ────────────────────────────────────────────────────────────────────────────────────────────────────────────
    llama-3.3-70b-instruct         79% 🟡   67% 🔴   68% 🔴   70% 🔴   65% 🔴   65% 🔴   66% 🔴   67% 🔴
    mistral-small-3.2-24b-ins      31% 🔴   36% 🔴   44% 🔴   44% 🔴   48% 🔴   49% 🔴   51% 🔴   51% 🔴
    qwen3-32b                      85% 🔵   73% 🔴   76% 🟡   75% 🔴   71% 🔴   72% 🔴   72% 🔴   72% 🔴
    qwen3-14b                      88% 🔵   81% 🟡   82% 🟡   79% 🟡   77% 🟡   75% 🔴   75% 🔴   75% 🟡
    qwen3-next-80b-a3b-instru      79% 🟡   78% 🟡   77% 🟡   75% 🔴   75% 🔴   75% 🔴   75% 🟡   76% 🟡

  [3b] Tool Name Acc
    모델                               ~T3     ~T5     ~T7    ~T10    ~T13    ~T15    ~T17    ~T19
    ────────────────────────────────────────────────────────────────────────────────────────────
    llama-3.3-70b-instruct          97%     85%     89%     90%     86%     85%     86%     86% 
    mistral-small-3.2-24b-ins       22%     24%     29%     33%     34%     37%     42%     43% 
    qwen3-32b                       89%     80%     82%     81%     75%     76%     76%     77% 
    qwen3-14b                       94%     91%     93%     88%     84%     81%     82%     83% 
    qwen3-next-80b-a3b-instru       83%     81%     78%     77%     75%     76%     77%     78% 

  [3c] Arg Value Acc
    모델                               ~T3     ~T5     ~T7    ~T10    ~T13    ~T15    ~T17    ~T19
    ────────────────────────────────────────────────────────────────────────────────────────────
    llama-3.3-70b-instruct          42%     38%     42%     38%     34%     34%     36%     37% 
    mistral-small-3.2-24b-ins       19%     21%     27%     29%     28%     29%     30%     31% 
    qwen3-32b                       74%     68%     72%     65%     59%     58%     56%     56% 
    qwen3-14b                       74%     74%     80%     71%     65%     62%     59%     59% 
    qwen3-next-80b-a3b-instru       64%     66%     65%     61%     58%     57%     58%     58% 

  [3d] FC Judgment
    모델                               ~T3     ~T5     ~T7    ~T10    ~T13    ~T15    ~T17    ~T19
    ────────────────────────────────────────────────────────────────────────────────────────────
    llama-3.3-70b-instruct          97%     83%     83%     87%     82%     83%     84%     84% 
    mistral-small-3.2-24b-ins       50%     53%     59%     59%     63%     64%     66%     67% 
    qwen3-32b                       93%     81%     82%     85%     83%     84%     84%     85% 
    qwen3-14b                       96%     88%     87%     88%     87%     86%     87%     87% 
    qwen3-next-80b-a3b-instru       89%     86%     85%     85%     85%     86%     86%     87% 

  [3e] Stress별 Performance 곡선
  → 동일 turn-point에서 어떤 스트레스 유형이 먼저 성능을 깎는지 비교

    [ST1 — 조건누적]
    모델                                 ~T3       ~T5       ~T7      ~T10      ~T13      ~T15      ~T17      ~T19
    ────────────────────────────────────────────────────────────────────────────────────────────────────────────
    llama-3.3-70b-instruct         73% 🔴   66% 🔴   68% 🔴   70% 🔴   66% 🔴   66% 🔴   67% 🔴   68% 🔴
    mistral-small-3.2-24b-ins      13% 🔴   21% 🔴   31% 🔴   41% 🔴   42% 🔴   49% 🔴   51% 🔴   53% 🔴
    qwen3-32b                      81% 🟡   74% 🔴   71% 🔴   66% 🔴   64% 🔴   68% 🔴   67% 🔴   69% 🔴
    qwen3-14b                      80% 🟡   81% 🟡   82% 🟡   74% 🔴   73% 🔴   71% 🔴   70% 🔴   71% 🔴
    qwen3-next-80b-a3b-instru      80% 🟡   88% 🔵   86% 🔵   81% 🟡   80% 🟡   79% 🟡   77% 🟡   78% 🟡

    [ST2 — 맥락희석]
    모델                                 ~T3       ~T5       ~T7      ~T10      ~T13      ~T15      ~T17      ~T19
    ────────────────────────────────────────────────────────────────────────────────────────────────────────────
    llama-3.3-70b-instruct         83% 🟡   66% 🔴   69% 🔴   70% 🔴   65% 🔴   63% 🔴   65% 🔴   65% 🔴
    mistral-small-3.2-24b-ins      41% 🔴   55% 🔴   62% 🔴   57% 🔴   61% 🔴   60% 🔴   63% 🔴   63% 🔴
    qwen3-32b                      95% 🟢   76% 🟡   81% 🟡   81% 🟡   74% 🔴   73% 🔴   74% 🔴   74% 🔴
    qwen3-14b                      94% 🟢   76% 🟡   78% 🟡   78% 🟡   74% 🔴   74% 🔴   75% 🔴   75% 🔴
    qwen3-next-80b-a3b-instru      93% 🟢   75% 🔴   82% 🟡   81% 🟡   80% 🟡   79% 🟡   80% 🟡   81% 🟡

    [ST3 — 교란주입]
    모델                                 ~T3       ~T5       ~T7      ~T10      ~T13      ~T15      ~T17      ~T19
    ────────────────────────────────────────────────────────────────────────────────────────────────────────────
    llama-3.3-70b-instruct         80% 🟡   69% 🔴   68% 🔴   68% 🔴   63% 🔴   65% 🔴   67% 🔴   67% 🔴
    mistral-small-3.2-24b-ins      38% 🔴   32% 🔴   40% 🔴   35% 🔴   39% 🔴   39% 🔴   39% 🔴   38% 🔴
    qwen3-32b                      80% 🟡   70% 🔴   74% 🔴   78% 🟡   77% 🟡   75% 🔴   74% 🔴   74% 🔴
    qwen3-14b                      91% 🟢   86% 🔵   85% 🟡   86% 🔵   84% 🟡   80% 🟡   80% 🟡   80% 🟡
    qwen3-next-80b-a3b-instru      63% 🔴   71% 🔴   62% 🔴   62% 🔴   65% 🔴   67% 🔴   70% 🔴   70% 🔴

    [Stress 민감도 요약]
      모델                              ST1    ST2    ST3     최대편차         최약
      ──────────────────────────── ────── ────── ────── ──────── ──────────
      llama-3.3-70b-instruct         68%   65%   67%   2.9%p  ST2(맥락희석)
      mistral-small-3.2-24b-ins      53%   63%   38%  25.5%p  ST3(교란주입)
      qwen3-32b                      69%   74%   74%   5.7%p  ST1(조건누적)
      qwen3-14b                      71%   75%   80%   8.7%p  ST1(조건누적)
      qwen3-next-80b-a3b-instru      78%   81%   70%  10.2%p  ST3(교란주입)

    [인사이트: tool 과잉 성향 ↔ 교란 내성]
      ST3 교란주입은 tool_call 턴이 ~89%를 차지한다.
      'tool 과잉' 모델은 no_call에 약하지만, 교란 후에도 주저 없이
      올바른 tool을 호출하므로 ST3 성능이 오히려 높다.

      모델                              NC정답    ST1    ST2    ST3     ST3이 최고?
      ──────────────────────────── ─────── ────── ────── ────── ────────────
      qwen3-14b                       33%   71%   75%   80%            ✓
      qwen3-32b                       42%   69%   74%   74%             
      llama-3.3-70b-instruct           0%   68%   65%   67%             
      ─── 비교: 균형 모델 ───
      qwen3-next-80b-a3b-instru       83%   78%   81%   70%
      → tool 과잉 성향은 교란 내성에서 유리하나,
        no_call 정확도를 희생하는 trade-off가 존재한다.
        프롬프트로 no_call 판별만 보강하면 양쪽 모두 잡을 수 있다.

  붕괴 순서: 인자(Arg) → 도구 선택(Tool) → 행동 판단(FC) (4/5 모델)

==============================================================================
  4. 원인 분석 — 무엇이 성능을 떨어뜨리는가?
==============================================================================

  6개 시나리오(O1/O2 × ST1/ST2/ST3)에서 '어떤 스트레스가 더 치명적인가' 비교.

  [스트레스 유형별 Performance]
    모델                             ST1(누적)   ST2(희석)   ST3(교란)       편차
    ──────────────────────────── ───────── ───────── ───────── ────────
    llama-3.3-70b-instruct          68.3%    65.2%    66.8%   3.1%p
    mistral-small-3.2-24b-ins       53.5%    61.6%    38.6%  23.0%p
    qwen3-32b                       68.6%    74.2%    74.1%   5.6%p
    qwen3-14b                       71.7%    74.2%    80.1% ◀   8.4%p
    qwen3-next-80b-a3b-instru       77.4% ◀    80.0% ◀    70.5%   9.5%p

  [콜 유형별 Tool Acc]
    모델                              O1(청약)    O2(보류)       차이
    ──────────────────────────── ───────── ───────── ────────
    llama-3.3-70b-instruct          84.1%    87.4%   3.3%p
    mistral-small-3.2-24b-ins       43.0%    42.7%   0.3%p
    qwen3-32b                       78.1%    76.3%   1.9%p
    qwen3-14b                       82.2%    83.9%   1.7%p
    qwen3-next-80b-a3b-instru       82.2%    73.9%   8.3%p

  → 치명적: 교란주입(ST3) / 안전: 맥락희석(ST2) / 청약 vs 보류 차이: 평균 3.1%p(미미)

==============================================================================
  4b. Error Taxonomy — 에러 유형 분류
==============================================================================

  각 턴의 실패를 6개 태그로 분류하여 '어떤 종류의 실수를 하는가' 진단.
  개선 방향: MISSED_CALL/FALSE_CALL → 프롬프트, ARG_* → 슬롯 메모리

  태그 정의:
    WRONG_TOOL     호출해야 하는데 다른 tool 호출
    MISSED_CALL    호출해야 하는데 호출 안 함
    FALSE_CALL     호출하면 안 되는데 호출
    ARG_MISSING    tool 맞지만 필수 인자 누락
    ARG_WRONG      tool 맞지만 인자 값 틀림
    ARG_STALE      번복값 미갱신 (ST3 추정)

  ----------------------------+----------+----------+----------+----------+----------+----------+--------+
  | 모델                        |   WRONG  |  MISSED  |   FALSE  |  ARG_MIS |  ARG_WR  |   STALE  |   OK   |
  |                           |   _TOOL  |   _CALL  |   _CALL  |   SING   |    ONG   |   (ST3)  |        |
  ----------------------------+----------+----------+----------+----------+----------+----------+--------+
  | llama-3.3-70b-instruct    |    19    |     0    |    12    |     5    |    40    |    21    |    9   |
  | mistral-small-3.2-24b-ins |     9    |    47    |     1    |     2    |    14    |     5    |   28   |
  | qwen3-32b                 |    23    |     2    |     7    |     0    |    25    |    13    |   36   |
  | qwen3-14b                 |    16    |     2    |     8    |     0    |    26    |    20    |   34   |
  | qwen3-next-80b-a3b-instru |    18    |     7    |     2    |     4    |    23    |    13    |   39   |
  ----------------------------+----------+----------+----------+----------+----------+----------+--------+

  [모델별 Top 에러 + 개선 방향]
    llama-3.3-70b-instruct       ARG_WRONG(40) > ARG_STALE(21)
                                 → slot memory (외부 JSON) 도입
    mistral-small-3.2-24b-ins    MISSED_CALL(47) > ARG_WRONG(14)
                                 → 프롬프트: '정보 있으면 tool 호출' 명시
    qwen3-32b                    ARG_WRONG(25) > WRONG_TOOL(23)
                                 → slot memory (외부 JSON) 도입
    qwen3-14b                    ARG_WRONG(26) > ARG_STALE(20)
                                 → slot memory (외부 JSON) 도입
    qwen3-next-80b-a3b-instru    ARG_WRONG(23) > WRONG_TOOL(18)
                                 → slot memory (외부 JSON) 도입

==============================================================================
  5. 모델 한 줄 프로필
==============================================================================

  ※ 실무(@T7) = 실제 콜 분량 기준 | 전체(@T19) = 스트레스 포함 전 구간

     llama-3.3-70b-instruct       실무 68% → 전체 67% (+2%p)  85%+: T3 미만
     Tool 86%  Arg 37%  FC 84%
     → 인자기억↓(49%p) | 복수호출 못함 | No-Call 취약
     mistral-small-3.2-24b-ins    실무 44% → 전체 51% (-7%p)  85%+: T3 미만
     Tool 43%  Arg 31%  FC 67%
     → NC높지만 tool자체 약함
  ⏳ qwen3-32b                    실무 76% → 전체 72% (+3%p)  85%+: ~T3
     Tool 77%  Arg 56%  FC 85%
     → No-Call 취약
  🏆 qwen3-14b                    실무 82% → 전체 75% (+6%p)  85%+: ~T3
     Tool 83%  Arg 59%  FC 87%
     → No-Call 취약
     qwen3-next-80b-a3b-instru    실무 77% → 전체 76% (+0%p)  85%+: T3 미만
     Tool 78%  Arg 58%  FC 87%
     → 균형

==============================================================================
  6. 결론 & 개선 로드맵
==============================================================================

  [모델 선정]
    → 1모델 권장: qwen3-14b
      실무 82% | NL 50% | Agent+답변 겸용 가능

  [현재 위치 — qwen3-14b @T7]
    Performance 82% = Tool 93% + Arg 80% + FC 96% (tool턴) / NC 33% (no-call턴)
    tool_call 36턴 (86%) + no_call 6턴 (14%)

  [민감도 분석 — 어디를 고치면 Performance가 가장 오르는가?]
    지표               현재       여유      민감도      최대 효과     우선순위
    ──────────── ────── ──────── ──────── ────────── ────────
    Arg Acc        80%    +15%p   +2.9%p     +4.2%p      ★★★
    No-Call        33%    +52%p   +1.4%p     +7.4%p      ★★★
    Tool Acc       93%     +5%p   +2.9%p     +1.4%p       ★★
    민감도=+10%p당 Perf 변화 | 최대 효과=여유분 전부 개선 시 Perf 변화
    → Arg Acc와 No-Call이 가장 효과적인 개선 레버

  [개선 로드맵 — 82% → 90%+]

    Phase 1 → 85% (Quick Win, 1~2주)
    ┌──────────────────────────────────────────────────────┐
    │  No-Call 33% → 56%                             │
    │  방법: 시스템 프롬프트에 no-call 가이드 추가           │
    │  '필수 정보가 부족하면 tool 대신 고객에게 질문하세요'   │
    │  + slot_question few-shot 2~3개                       │
    └──────────────────────────────────────────────────────┘

    Phase 2 → 90% (Prompt Engineering, 2~4주)
    ┌──────────────────────────────────────────────────────┐
    │  Arg Acc 80% → 90%+                              │
    │  방법: structured slot tracking 프롬프트 도입          │
    │  '고객 정보를 JSON으로 누적 추적하고, tool 호출 시      │
    │   반드시 해당 JSON에서 인자를 채워 넣으세요'            │
    │  + No-Call 56% → 80%+ (few-shot 보강)              │
    └──────────────────────────────────────────────────────┘

    Phase 3 → 95% (고도화)
    ┌──────────────────────────────────────────────────────┐
    │  Arg Acc → 95%+ (Chain-of-Thought 인자 검증 단계)     │
    │  No-Call → 90%+ (경계 케이스 few-shot 확대)           │
    │  Parallel → 순차 분리 호출로 전환 (현재 인식률 50%)  │
    │  ※ 95%는 프롬프트만으로 한계 → fine-tune 검토 필요     │
    └──────────────────────────────────────────────────────┘

  [운영 가이드]
    • 턴 제한: 실무 7턴 이내 (현재 82%, 충분히 활용 가능)
    • T7 이후 성능 하락은 스트레스 테스트 결과이며, 운영 목표 아님
    • 개선 후 이 벤치마크 재실행 → Phase별 달성 여부 확인

==============================================================================