==============================================================================
  AI TMR Assistant — 모델 성능 비교 리포트
==============================================================================
  생성: 2026-02-10 00:59 | 턴: 106 × 5모델 | Judge: openai/gpt-4o
  commit: 558487b | run_id: 20260210_005948
  config:   seed=44  temp=0.0  tool_choice=auto
  config:   judge: seed=44  temp=0.0  max_tokens=200

  용어 정의:
    @T7 (실무 구간) = Turn 1~7까지의 누적 성능. TMR 영업콜의
    실무 턴 수(청약 ~7턴, 보류 ~5턴)에 대응하는 운영 기준선.
    T7 이후(T10~T19)는 스트레스 테스트 구간으로 내구도 진단용.

==============================================================================
  실무 기준(7턴) 1위: qwen3-14b  Performance 76%
  병목: Arg Acc 73% / No-Call 33%  |  NL 1위: qwen3-14b (60%)
  → 1모델 권장: qwen3-14b (Agent+답변 겸용)
==============================================================================
  ※ 본 벤치마크는 최대 19턴 스트레스 테스트를 포함합니다.
    실무 TMR 콜은 보통 5~7턴이므로, @T7 누적을 실무 성능으로 봅니다.
    T7 이후는 내구도 진단용이며, 운영 목표 수치가 아닙니다.

==============================================================================
  1. 모델별 성적표
==============================================================================

  Tool Acc = tool 호출 정답률 (94턴)
  Arg Acc  = 인자 정확도 (tool name 정답일 때만)
  FC Judge = 행동 판단 정확도 (전체 106턴)
  NL Qual  = 자연어 답변 품질 (LLM Judge, 텍스트 있는 턴만)
  Perf     = 종합 (tool턴: (Tool+Arg+FC)/3, no-call턴: FC)
  ※ 실무 = ~T7 누적 | 전체 = ~T19 누적 (스트레스 포함)

  모델                              Tool     Arg      FC      NL    │ 실무     전체    Gap
  ──────────────────────────── ─────── ─────── ─────── ─────── ─────── ────── ──────
  llama-3.3-70b-instruct        84.6%  48.5%  84.1%   N/A  │  73%   70%   +3%p
  mistral-small-3.2-24b-ins      0.0%   0.0%  39.9%    15% │  24%   21%   +3%p ◀ ✗
  qwen3-32b                     77.7%  59.7%  86.2%    57% │  76%   74%   +1%p
  qwen3-14b                     83.0%  60.3%  87.7%    60% │  76%   76%   +1%p ◀ Agent1위,NL1위
  qwen3-next-80b-a3b-instru     77.7%  61.5%  85.5%    30% │  78%   76%   +1%p

  ※ 전체 Perf 1위는 qwen3-next-80b-a3b-instru(실무 78% → 전체 76%)이나,
    qwen3-14b(실무 76% → 전체 76%)가 85%+ ~T3까지 유지 → Agent 1위.

  [1위 모델 실무 구간(@T7) 세부]
    대상: qwen3-14b | 실무 턴: 42턴 (tool_call 36 + no_call 6)
    Tool Acc    85%  ← 양호
    Arg Acc     73%  ← 🔴 병목
    FC Judge    93%  ← 이미 우수
    No-Call     33%  ← 🔴 병목
    ─────────────────────
    Perf        76%
    → 개선 우선순위: No-Call(33%) > Arg Acc(73%)

==============================================================================
  2. 능력 해부 — Single / Parallel / No-Call
==============================================================================

  [Single — tool 1개 호출 (82턴)]
    모델                             tool 정답      인자 정답
    ──────────────────────────── ───────── ──────────
    llama-3.3-70b-instruct            90%       52%
    mistral-small-3.2-24b-ins          0%        0%
    qwen3-32b                         83%       65%
    qwen3-14b                         87%       65%
    qwen3-next-80b-a3b-instru         82%       65%

  [Parallel — tool 2개 동시 호출 (12턴)]
    모델                             tool 정답      인자 정답     2개 인식
    ──────────────────────────── ───────── ────────── ─────────
    llama-3.3-70b-instruct            46%       24%       0%
    mistral-small-3.2-24b-ins          0%        0%       0%
    qwen3-32b                         42%       23%      17%
    qwen3-14b                         58%       29%      50%
    qwen3-next-80b-a3b-instru         50%       38%       8%
    → 최고 50%. 실서비스에서는 1개씩 분리 호출 필요.

  [No-Call — tool 안 불러야 정답 (12턴)]
    모델                                미호출 정답      질문      거부       누락 전부 질문       텍스트 품질
    ──────────────────────────── ─────────── ─────── ─────── ────────────── ────────────
    llama-3.3-70b-instruct               0%     0%     0%            0%         N/A
    mistral-small-3.2-24b-ins          100%   100%   100%           14%         20%
    qwen3-32b                           50%    17%    83%            6%         67%
    qwen3-14b                           33%     0%    67%            0%         75%
    qwen3-next-80b-a3b-instru           83%    67%   100%           11%         30%
    ⚠ mistral-small-3.2-24b-ins: 100%이지만 tool 자체를 못 불러서 높은 것 (의미 없음)
    ⚠ llama-3.3-70b-instruct, qwen3-14b: 정보 부족해도 tool 호출 → 위험

  [No-Call vs Tool 호출 — trade-off 분석]
    모델                            Tool Acc    NC 정답             성향
    ──────────────────────────── ───────── ──────── ──────────────
    llama-3.3-70b-instruct            85%      0%        tool 과잉
    qwen3-32b                         78%     50%              -
    qwen3-14b                         83%     33%        tool 과잉
    qwen3-next-80b-a3b-instru         78%     83%             균형
    → tool 과잉 (2개 모델): No-Call 정확도가 낮아 불필요한 tool 호출 발생

==============================================================================
  3. 성능 곡선 — 몇 턴까지 85%를 유지하는가?
==============================================================================

  시나리오를 T3~T19 지점에서 잘라 누적 평균을 계산한다.
  🟢 90%+ | 🔵 85%+ | 🟡 75%+ | 🔴 <75%  (85% = 절대 임계선)

  [3a] Performance 종합
    모델                                 ~T3       ~T5       ~T7      ~T10      ~T13      ~T15      ~T17      ~T19
    ────────────────────────────────────────────────────────────────────────────────────────────────────────────
    llama-3.3-70b-instruct         87% 🔵   73% 🔴   73% 🔴   74% 🔴   68% 🔴   68% 🔴   70% 🔴   70% 🔴
    mistral-small-3.2-24b-ins      11% 🔴   20% 🔴   24% 🔴   20% 🔴   23% 🔴   23% 🔴   21% 🔴   21% 🔴
    qwen3-32b                      90% 🟢   71% 🔴   76% 🟡   77% 🟡   75% 🟡   76% 🟡   74% 🔴   74% 🔴
    qwen3-14b                      85% 🔵   76% 🟡   76% 🟡   76% 🟡   73% 🔴   74% 🔴   75% 🟡   76% 🟡
    qwen3-next-80b-a3b-instru      82% 🟡   80% 🟡   78% 🟡   77% 🟡   76% 🟡   76% 🟡   76% 🟡   76% 🟡

  [3b] Tool Name Acc
    모델                               ~T3     ~T5     ~T7    ~T10    ~T13    ~T15    ~T17    ~T19
    ────────────────────────────────────────────────────────────────────────────────────────────
    llama-3.3-70b-instruct          97%     85%     89%     90%     84%     83%     85%     85% 
    mistral-small-3.2-24b-ins        0%      0%      0%      0%      0%      0%      0%      0% 
    qwen3-32b                       94%     76%     82%     83%     78%     79%     76%     78% 
    qwen3-14b                       89%     83%     85%     82%     80%     80%     82%     83% 
    qwen3-next-80b-a3b-instru       86%     83%     79%     80%     76%     76%     76%     78% 

  [3c] Arg Value Acc
    모델                               ~T3     ~T5     ~T7    ~T10    ~T13    ~T15    ~T17    ~T19
    ────────────────────────────────────────────────────────────────────────────────────────────
    llama-3.3-70b-instruct          66%     57%     59%     52%     47%     48%     48%     48% 
    mistral-small-3.2-24b-ins        0%      0%      0%      0%      0%      0%      0%      0% 
    qwen3-32b                       79%     64%     70%     67%     63%     63%     59%     60% 
    qwen3-14b                       72%     67%     73%     66%     60%     60%     60%     60% 
    qwen3-next-80b-a3b-instru       69%     71%     69%     66%     61%     61%     61%     62% 

  [3d] FC Judgment
    모델                               ~T3     ~T5     ~T7    ~T10    ~T13    ~T15    ~T17    ~T19
    ────────────────────────────────────────────────────────────────────────────────────────────
    llama-3.3-70b-instruct          97%     83%     83%     87%     82%     82%     84%     84% 
    mistral-small-3.2-24b-ins       33%     40%     43%     39%     42%     41%     40%     40% 
    qwen3-32b                       98%     82%     84%     87%     85%     86%     85%     86% 
    qwen3-14b                       94%     86%     85%     86%     85%     86%     87%     88% 
    qwen3-next-80b-a3b-instru       90%     86%     85%     86%     84%     85%     85%     86% 

  [3e] Stress별 Performance 곡선
  → 동일 turn-point에서 어떤 스트레스 유형이 먼저 성능을 깎는지 비교

    [ST1 — 조건누적]
    모델                                 ~T3       ~T5       ~T7      ~T10      ~T13      ~T15      ~T17      ~T19
    ────────────────────────────────────────────────────────────────────────────────────────────────────────────
    llama-3.3-70b-instruct         83% 🟡   72% 🔴   74% 🔴   76% 🟡   72% 🔴   72% 🔴   72% 🔴   73% 🔴
    mistral-small-3.2-24b-ins      11% 🔴   20% 🔴   24% 🔴   20% 🔴   21% 🔴   23% 🔴   22% 🔴   21% 🔴
    qwen3-32b                      82% 🟡   59% 🔴   65% 🔴   71% 🔴   69% 🔴   72% 🔴   68% 🔴   69% 🔴
    qwen3-14b                      68% 🔴   67% 🔴   66% 🔴   59% 🔴   61% 🔴   65% 🔴   66% 🔴   68% 🔴
    qwen3-next-80b-a3b-instru      73% 🔴   84% 🟡   81% 🟡   83% 🟡   77% 🟡   77% 🟡   75% 🟡   76% 🟡

    [ST2 — 맥락희석]
    모델                                 ~T3       ~T5       ~T7      ~T10      ~T13      ~T15      ~T17      ~T19
    ────────────────────────────────────────────────────────────────────────────────────────────────────────────
    llama-3.3-70b-instruct         90% 🟢   71% 🔴   72% 🔴   73% 🔴   68% 🔴   66% 🔴   67% 🔴   67% 🔴
    mistral-small-3.2-24b-ins      11% 🔴   20% 🔴   24% 🔴   19% 🔴   24% 🔴   22% 🔴   21% 🔴   21% 🔴
    qwen3-32b                      94% 🟢   75% 🟡   82% 🟡   81% 🟡   77% 🟡   76% 🟡   75% 🟡   75% 🟡
    qwen3-14b                      95% 🟢   76% 🟡   78% 🟡   82% 🟡   75% 🟡   75% 🟡   76% 🟡   76% 🟡
    qwen3-next-80b-a3b-instru      94% 🟢   76% 🟡   83% 🟡   81% 🟡   80% 🟡   80% 🟡   80% 🟡   81% 🟡

    [ST3 — 교란주입]
    모델                                 ~T3       ~T5       ~T7      ~T10      ~T13      ~T15      ~T17      ~T19
    ────────────────────────────────────────────────────────────────────────────────────────────────────────────
    llama-3.3-70b-instruct         89% 🔵   75% 🟡   73% 🔴   73% 🔴   65% 🔴   67% 🔴   70% 🔴   69% 🔴
    mistral-small-3.2-24b-ins      11% 🔴   20% 🔴   24% 🔴   19% 🔴   24% 🔴   23% 🔴   21% 🔴   21% 🔴
    qwen3-32b                      94% 🟢   79% 🟡   80% 🟡   79% 🟡   78% 🟡   78% 🟡   79% 🟡   79% 🟡
    qwen3-14b                      92% 🟢   86% 🔵   85% 🔵   85% 🔵   84% 🟡   83% 🟡   83% 🟡   83% 🟡
    qwen3-next-80b-a3b-instru      77% 🟡   81% 🟡   69% 🔴   68% 🔴   70% 🔴   71% 🔴   72% 🔴   72% 🔴

    [Stress 민감도 요약]
      모델                              ST1    ST2    ST3     최대편차         최약
      ──────────────────────────── ────── ────── ────── ──────── ──────────
      llama-3.3-70b-instruct         73%   67%   69%   6.3%p  ST2(맥락희석)
      qwen3-32b                      69%   75%   78%   9.2%p  ST1(조건누적)
      qwen3-14b                      68%   76%   83%  15.6%p  ST1(조건누적)
      qwen3-next-80b-a3b-instru      76%   81%   72%   8.5%p  ST3(교란주입)

    [인사이트: tool 과잉 성향 ↔ 교란 내성]
      ST3 교란주입은 tool_call 턴이 ~89%를 차지한다.
      'tool 과잉' 모델은 no_call에 약하지만, 교란 후에도 주저 없이
      올바른 tool을 호출하므로 ST3 성능이 오히려 높다.

      모델                              NC정답    ST1    ST2    ST3     ST3이 최고?
      ──────────────────────────── ─────── ────── ────── ────── ────────────
      qwen3-14b                       33%   68%   76%   83%            ✓
      llama-3.3-70b-instruct           0%   73%   67%   69%             
      ─── 비교: 균형 모델 ───
      qwen3-next-80b-a3b-instru       83%   76%   81%   72%
      → tool 과잉 성향은 교란 내성에서 유리하나,
        no_call 정확도를 희생하는 trade-off가 존재한다.

  붕괴 순서: 인자(Arg) → 도구 선택(Tool) → 행동 판단(FC) (3/4 모델)

==============================================================================
  4. 원인 분석 — 무엇이 성능을 떨어뜨리는가?
==============================================================================

  6개 시나리오(O1/O2 × ST1/ST2/ST3)에서 '어떤 스트레스가 더 치명적인가' 비교.

  [스트레스 유형별 Performance]
    모델                             ST1(누적)   ST2(희석)   ST3(교란)       편차
    ──────────────────────────── ───────── ───────── ───────── ────────
    llama-3.3-70b-instruct          73.3%    67.0%    69.1%   6.3%p
    mistral-small-3.2-24b-ins       21.0%    20.9%    20.7%   0.3%p
    qwen3-32b                       69.2%    75.0%    78.5%   9.2%p
    qwen3-14b                       67.8%    75.8%    83.4% ◀  15.6%p
    qwen3-next-80b-a3b-instru       76.4% ◀    80.5% ◀    72.0%   8.5%p

  [콜 유형별 Tool Acc]
    모델                              O1(청약)    O2(보류)       차이
    ──────────────────────────── ───────── ───────── ────────
    llama-3.3-70b-instruct          84.1%    85.2%   1.1%p
    mistral-small-3.2-24b-ins        0.0%     0.0%   0.0%p
    qwen3-32b                       82.0%    72.8%   9.3%p
    qwen3-14b                       86.1%    79.6%   6.5%p
    qwen3-next-80b-a3b-instru       82.2%    72.8%   9.5%p

  → 가장 치명적: 조건누적(ST1) — usable 4개 모델 중 2개가 최약
    청약 vs 보류 차이: 평균 5.3%p(미미) → 변별력은 스트레스 유형(ST1/ST2/ST3)에 있음

==============================================================================
  4b. Error Taxonomy — 에러 유형 분류
==============================================================================

  각 턴의 실패를 6개 태그로 분류하여 '어떤 종류의 실수를 하는가' 진단.
  개선 방향: 각 에러 유형의 Top 태그를 우선 개선.

  태그 정의:
    WRONG_TOOL     호출해야 하는데 다른 tool 호출
    MISSED_CALL    호출해야 하는데 호출 안 함
    FALSE_CALL     호출하면 안 되는데 호출
    ARG_MISSING    tool 맞지만 필수 인자 누락
    ARG_WRONG      tool 맞지만 인자 값 틀림
    ARG_STALE      번복값 미갱신 (ST3 추정)

  ----------------------------+----------+----------+----------+----------+----------+----------+--------+
  | 모델                        |   WRONG  |  MISSED  |   FALSE  |  ARG_MIS |  ARG_WR  |   STALE  |   OK   |
  |                           |   _TOOL  |   _CALL  |   _CALL  |   SING   |    ONG   |   (ST3)  |        |
  ----------------------------+----------+----------+----------+----------+----------+----------+--------+
  | llama-3.3-70b-instruct    |    20    |     0    |    12    |     4    |    42    |    16    |   12   |
  | mistral-small-3.2-24b-ins |     0    |    94    |     0    |     0    |     0    |     0    |   12   |
  | qwen3-32b                 |    24    |     1    |     6    |     6    |    22    |     8    |   39   |
  | qwen3-14b                 |    17    |     1    |     8    |     4    |    24    |    17    |   35   |
  | qwen3-next-80b-a3b-instru |    16    |    10    |     2    |     6    |    18    |    10    |   44   |
  ----------------------------+----------+----------+----------+----------+----------+----------+--------+

  [모델별 Top 에러 + 개선 방향]
    llama-3.3-70b-instruct       ARG_WRONG(42) > WRONG_TOOL(20)
                                 → 인자 값 정확도 향상
    qwen3-32b                    WRONG_TOOL(24) > ARG_WRONG(22)
                                 → tool description 개선 또는 tool 선택 정확도 향상
    qwen3-14b                    ARG_WRONG(24) > WRONG_TOOL(17)
                                 → 인자 값 정확도 향상
    qwen3-next-80b-a3b-instru    ARG_WRONG(18) > WRONG_TOOL(16)
                                 → 인자 값 정확도 향상

  [1위 모델(qwen3-14b) 에러 인사이트]
    전체 106턴 중 완벽 정답 35턴 (33%)

    ● 핵심 약점 — 인자 오류 41건 (39%)
      ARG_WRONG(24) + ARG_STALE(17):
      tool은 맞게 골랐지만 인자 값을 틀림.
      특히 STALE 17건은 고객이 값을 번복한 뒤
      이전 값을 갱신하지 못한 실수 → 대화 상태 추적 실패.

    ● tool 혼동 — WRONG_TOOL 17건
      정답과 유사한 다른 tool을 호출하는 실수.

    ● No-Call 실패 — FALSE_CALL 8건
      정보 부족/범위 밖 상황에서 tool을 호출해버림.

    한 줄 요약: 최다 에러는 ARG_WRONG(24건) → Arg Acc 개선이 최우선.

==============================================================================
  5. 모델별 판정
==============================================================================

     qwen3-next-80b-a3b-instru — 조건부 사용 (실무 78%)
    + No-Call 83%로 상황 판단이 정확 (균형형)
    - 인자 오류 28건(번복 미갱신 10건 포함) — 값을 채우는 정밀도 부족
    - tool 혼동 16건 — 유사 tool 간 구분 실패

  🏆 qwen3-14b — 권장 (실무 76%)
    + 실무 76%로 1위
    - 인자 오류 41건(번복 미갱신 17건 포함) — 값을 채우는 정밀도 부족
    - tool 혼동 17건 — 유사 tool 간 구분 실패
    - No-Call 33% — 불러야/말아야 판단 부족 (tool 과잉)
    - 조건누적(ST1)에 약함 (68%, 최강 교란주입 83%과 16%p 차이)

     qwen3-32b — 조건부 사용 (실무 76%)
    - 인자 오류 30건(번복 미갱신 8건 포함) — 값을 채우는 정밀도 부족
    - tool 혼동 24건 — 유사 tool 간 구분 실패

     llama-3.3-70b-instruct — 조건부 사용 (실무 73%)
    + 호출 누락 0건 — tool을 적극적으로 부름
    - 인자 오류 58건(번복 미갱신 16건 포함) — 값을 채우는 정밀도 부족
    - tool 혼동 20건 — 유사 tool 간 구분 실패
    - No-Call 0% — 불러야/말아야 판단 부족 (tool 과잉)
    - Tool 85% vs Arg 48% — tool은 맞추지만 인자를 절반 이상 틀림
    - 복수호출 인식 0%

  ❌ mistral-small-3.2-24b-ins — 사용 불가 (실무 24%)
    tool 호출 자체를 거의 못 함 (Tool 0%).
    No-Call 100%는 tool을 못 불러서 높은 것이지,
    판단이 좋은 게 아님.

==============================================================================
  6. 결론
==============================================================================

  [현재 위치 — qwen3-14b @T7]
    Performance 76% = Tool 85% + Arg 73% + FC 93% (tool턴) / NC 33% (no-call턴)
    tool_call 36턴 (86%) + no_call 6턴 (14%)

  [민감도 분석 — 어디를 고치면 Performance가 가장 오르는가?]
    지표               현재       여유      민감도      최대 효과     우선순위
    ──────────── ────── ──────── ──────── ────────── ────────
    Arg Acc        73%    +22%p   +2.9%p     +6.4%p      ★★★
    No-Call        33%    +52%p   +1.4%p     +7.4%p      ★★★
    Tool Acc       85%    +13%p   +2.9%p     +3.8%p       ★★
    민감도=+10%p당 Perf 변화 | 최대 효과=여유분 전부 개선 시 Perf 변화
    → No-Call와 Arg Acc이 가장 효과적인 개선 레버

  [운영 가이드]
    • 턴 제한: 실무 7턴 이내 (현재 76%, 충분히 활용 가능)
    • T7 이후 성능 하락은 스트레스 테스트 결과이며, 운영 목표 아님
    • 개선 후 이 벤치마크 재실행 → 달성 여부 확인

==============================================================================