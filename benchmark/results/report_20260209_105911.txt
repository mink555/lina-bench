==============================================================================
  AI TMR Assistant — 모델 성능 비교 리포트
==============================================================================
  생성: 2026-02-09 13:31 | 턴: 106 × 5모델 | Judge: openai/gpt-4o
  commit: 2e5267c | run_id: 20260209_105911
  config:   seed=42  temp=0.0  tool_choice=auto
  config:   judge: seed=42  temp=0.0  max_tokens=200

  용어 정의:
    @T7 (실무 구간) = Turn 1~7까지의 누적 성능. TMR 영업콜의
    실무 턴 수(청약 ~7턴, 보류 ~5턴)에 대응하는 운영 기준선.
    T7 이후(T10~T19)는 스트레스 테스트 구간으로 내구도 진단용.

==============================================================================
  실무 기준(7턴) 1위: qwen3-14b  Performance 79%
  병목: Arg Acc 74% / No-Call 44%  |  NL 1위: qwen3-14b (100%)
  → 1모델 권장: qwen3-14b (Agent+답변 겸용)
==============================================================================
  ※ 본 벤치마크는 최대 19턴 스트레스 테스트를 포함합니다.
    실무 TMR 콜은 보통 5~7턴이므로, @T7 누적을 실무 성능으로 봅니다.
    T7 이후는 내구도 진단용이며, 운영 목표 수치가 아닙니다.

==============================================================================
  1. 모델별 성적표
==============================================================================

  Tool Acc = tool 호출 정답률 (94턴)
  Arg Acc  = 인자 정확도 (tool name 정답일 때만)
  FC Judge = 행동 판단 정확도 (전체 106턴)
  NL Qual  = 자연어 답변 품질 (LLM Judge, 텍스트 있는 턴만)
  Perf     = 종합 (tool턴: (Tool+Arg+FC)/3, no-call턴: FC)
  ※ 실무 = ~T7 누적 | 전체 = ~T19 누적 (스트레스 포함)

  모델                              Tool     Arg      FC      NL    │ 실무     전체    Gap
  ──────────────────────────── ─────── ─────── ─────── ─────── ─────── ────── ──────
  llama-3.3-70b-instruct        85.6%  36.5%  84.1%     0% │  68%   67%   +2%p
  mistral-small-3.2-24b-ins      8.5%   7.1%  45.3%    32% │  26%   27%   -1%p ◀ ✗
  qwen3-32b                     75.0%  58.0%  84.4%    83% │  75%   72%   +4%p
  qwen3-14b                     84.0%  62.0%  88.7%   100% │  79%   77%   +3%p ◀ Agent1위,NL1위
  qwen3-next-80b-a3b-instru     77.1%  58.8%  85.7%    26% │  77%   75%   +1%p


  [1위 모델 실무 구간(@T7) 세부]
    대상: qwen3-14b | 실무 턴: 42턴 (tool_call 36 + no_call 6)
    Tool Acc    88%  ← 이미 우수
    Arg Acc     74%  ← 🔴 병목
    FC Judge    94%  ← 이미 우수
    No-Call     44%  ← 🔴 병목
    ─────────────────────
    Perf        79%
    → 개선 우선순위: No-Call(44%) > Arg Acc(74%)

==============================================================================
  2. 능력 해부 — Single / Parallel / No-Call
==============================================================================

  [Single — tool 1개 호출 (82턴)]
    모델                             tool 정답      인자 정답
    ──────────────────────────── ───────── ──────────
    llama-3.3-70b-instruct            91%       39%
    mistral-small-3.2-24b-ins          9%        8%
    qwen3-32b                         79%       63%
    qwen3-14b                         87%       66%
    qwen3-next-80b-a3b-instru         80%       62%

  [Parallel — tool 2개 동시 호출 (12턴)]
    모델                             tool 정답      인자 정답     2개 인식
    ──────────────────────────── ───────── ────────── ─────────
    llama-3.3-70b-instruct            46%       21%       0%
    mistral-small-3.2-24b-ins          8%        3%       8%
    qwen3-32b                         46%       25%      33%
    qwen3-14b                         67%       37%      58%
    qwen3-next-80b-a3b-instru         54%       35%      17%
    → 최고 58%. 실서비스에서는 1개씩 분리 호출 필요.

  [No-Call — tool 안 불러야 정답 (12턴)]
    모델                                미호출 정답      질문      거부       누락 전부 질문       텍스트 품질
    ──────────────────────────── ─────────── ─────── ─────── ────────────── ────────────
    llama-3.3-70b-instruct               0%     0%     0%            0%         N/A
    mistral-small-3.2-24b-ins          100%   100%   100%           36%         20%
    qwen3-32b                           33%    17%    50%           11%         75%
    qwen3-14b                           33%    17%    50%            0%        100%
    qwen3-next-80b-a3b-instru           83%    67%   100%            6%         40%
    ⚠ mistral-small-3.2-24b-ins: 100%이지만 tool 자체를 못 불러서 높은 것 (의미 없음)
    ⚠ llama-3.3-70b-instruct, qwen3-32b, qwen3-14b: 정보 부족해도 tool 호출 → 위험

  [No-Call vs Tool 호출 — trade-off 분석]
    모델                            Tool Acc    NC 정답             성향
    ──────────────────────────── ───────── ──────── ──────────────
    llama-3.3-70b-instruct            86%      0%        tool 과잉
    qwen3-32b                         75%     33%        tool 과잉
    qwen3-14b                         84%     33%        tool 과잉
    qwen3-next-80b-a3b-instru         77%     83%             균형
    → tool 과잉 (3개 모델): No-Call 정확도가 낮아 불필요한 tool 호출 발생

==============================================================================
  3. 성능 곡선 — 몇 턴까지 85%를 유지하는가?
==============================================================================

  시나리오를 T3~T19 지점에서 잘라 누적 평균을 계산한다.
  🟢 90%+ | 🔵 85%+ | 🟡 75%+ | 🔴 <75%  (85% = 절대 임계선)

  [3a] Performance 종합
    모델                                 ~T3       ~T5       ~T7      ~T10      ~T13      ~T15      ~T17      ~T19
    ────────────────────────────────────────────────────────────────────────────────────────────────────────────
    llama-3.3-70b-instruct         79% 🟡   67% 🔴   68% 🔴   70% 🔴   65% 🔴   66% 🔴   66% 🔴   67% 🔴
    mistral-small-3.2-24b-ins      11% 🔴   20% 🔴   26% 🔴   22% 🔴   28% 🔴   27% 🔴   26% 🔴   27% 🔴
    qwen3-32b                      85% 🔵   71% 🔴   75% 🟡   75% 🟡   72% 🔴   72% 🔴   71% 🔴   72% 🔴
    qwen3-14b                      89% 🔵   80% 🟡   79% 🟡   81% 🟡   77% 🟡   76% 🟡   76% 🟡   77% 🟡
    qwen3-next-80b-a3b-instru      74% 🔴   75% 🟡   77% 🟡   76% 🟡   76% 🟡   75% 🟡   75% 🟡   75% 🟡

  [3b] Tool Name Acc
    모델                               ~T3     ~T5     ~T7    ~T10    ~T13    ~T15    ~T17    ~T19
    ────────────────────────────────────────────────────────────────────────────────────────────
    llama-3.3-70b-instruct          97%     85%     89%     90%     86%     86%     85%     86% 
    mistral-small-3.2-24b-ins        0%      0%      3%      4%      6%      6%      7%      9% 
    qwen3-32b                       89%     76%     82%     80%     75%     76%     75%     75% 
    qwen3-14b                       94%     87%     88%     89%     84%     83%     83%     84% 
    qwen3-next-80b-a3b-instru       78%     78%     78%     79%     77%     76%     76%     77% 

  [3c] Arg Value Acc
    모델                               ~T3     ~T5     ~T7    ~T10    ~T13    ~T15    ~T17    ~T19
    ────────────────────────────────────────────────────────────────────────────────────────────
    llama-3.3-70b-instruct          42%     38%     42%     38%     34%     35%     35%     36% 
    mistral-small-3.2-24b-ins        0%      0%      3%      3%      6%      6%      5%      7% 
    qwen3-32b                       73%     63%     71%     66%     61%     60%     57%     58% 
    qwen3-14b                       74%     70%     74%     72%     65%     63%     61%     62% 
    qwen3-next-80b-a3b-instru       59%     63%     67%     62%     59%     58%     58%     59% 

  [3d] FC Judgment
    모델                               ~T3     ~T5     ~T7    ~T10    ~T13    ~T15    ~T17    ~T19
    ────────────────────────────────────────────────────────────────────────────────────────────
    llama-3.3-70b-instruct          97%     83%     83%     87%     82%     83%     83%     84% 
    mistral-small-3.2-24b-ins       33%     40%     44%     41%     46%     45%     45%     45% 
    qwen3-32b                       93%     79%     82%     84%     84%     84%     84%     84% 
    qwen3-14b                       98%     89%     87%     89%     88%     88%     88%     89% 
    qwen3-next-80b-a3b-instru       85%     83%     84%     86%     86%     85%     85%     86% 

  [3e] Stress별 Performance 곡선
  → 동일 turn-point에서 어떤 스트레스 유형이 먼저 성능을 깎는지 비교

    [ST1 — 조건누적]
    모델                                 ~T3       ~T5       ~T7      ~T10      ~T13      ~T15      ~T17      ~T19
    ────────────────────────────────────────────────────────────────────────────────────────────────────────────
    llama-3.3-70b-instruct         73% 🔴   66% 🔴   68% 🔴   70% 🔴   67% 🔴   67% 🔴   64% 🔴   65% 🔴
    mistral-small-3.2-24b-ins      11% 🔴   20% 🔴   30% 🔴   29% 🔴   35% 🔴   37% 🔴   36% 🔴   40% 🔴
    qwen3-32b                      79% 🟡   65% 🔴   69% 🔴   70% 🔴   68% 🔴   67% 🔴   64% 🔴   66% 🔴
    qwen3-14b                      81% 🟡   74% 🔴   71% 🔴   72% 🔴   72% 🔴   73% 🔴   71% 🔴   72% 🔴
    qwen3-next-80b-a3b-instru      80% 🟡   88% 🔵   91% 🟢   90% 🟢   86% 🔵   85% 🔵   82% 🟡   83% 🟡

    [ST2 — 맥락희석]
    모델                                 ~T3       ~T5       ~T7      ~T10      ~T13      ~T15      ~T17      ~T19
    ────────────────────────────────────────────────────────────────────────────────────────────────────────────
    llama-3.3-70b-instruct         83% 🟡   66% 🔴   69% 🔴   70% 🔴   65% 🔴   66% 🔴   67% 🔴   67% 🔴
    mistral-small-3.2-24b-ins      11% 🔴   20% 🔴   24% 🔴   19% 🔴   24% 🔴   22% 🔴   21% 🔴   21% 🔴
    qwen3-32b                      96% 🟢   76% 🟡   83% 🟡   82% 🟡   75% 🟡   77% 🟡   77% 🟡   78% 🟡
    qwen3-14b                      94% 🟢   86% 🔵   85% 🔵   87% 🔵   78% 🟡   75% 🟡   75% 🟡   76% 🟡
    qwen3-next-80b-a3b-instru      80% 🟡   67% 🔴   76% 🟡   78% 🟡   78% 🟡   74% 🔴   76% 🟡   76% 🟡

    [ST3 — 교란주입]
    모델                                 ~T3       ~T5       ~T7      ~T10      ~T13      ~T15      ~T17      ~T19
    ────────────────────────────────────────────────────────────────────────────────────────────────────────────
    llama-3.3-70b-instruct         80% 🟡   69% 🔴   68% 🔴   68% 🔴   63% 🔴   64% 🔴   67% 🔴   68% 🔴
    mistral-small-3.2-24b-ins      11% 🔴   20% 🔴   24% 🔴   19% 🔴   24% 🔴   23% 🔴   21% 🔴   21% 🔴
    qwen3-32b                      80% 🟡   70% 🔴   74% 🔴   72% 🔴   74% 🔴   72% 🔴   73% 🔴   72% 🔴
    qwen3-14b                      91% 🟢   81% 🟡   82% 🟡   84% 🟡   83% 🟡   81% 🟡   82% 🟡   82% 🟡
    qwen3-next-80b-a3b-instru      63% 🔴   71% 🔴   63% 🔴   60% 🔴   63% 🔴   65% 🔴   67% 🔴   68% 🔴

    [Stress 민감도 요약]
      모델                              ST1    ST2    ST3     최대편차         최약
      ──────────────────────────── ────── ────── ────── ──────── ──────────
      llama-3.3-70b-instruct         65%   67%   68%   2.1%p  ST1(조건누적)
      qwen3-32b                      66%   78%   72%  12.1%p  ST1(조건누적)
      qwen3-14b                      73%   76%   82%   9.8%p  ST1(조건누적)
      qwen3-next-80b-a3b-instru      83%   76%   68%  15.1%p  ST3(교란주입)

    [인사이트: tool 과잉 성향 ↔ 교란 내성]
      ST3 교란주입은 tool_call 턴이 ~89%를 차지한다.
      'tool 과잉' 모델은 no_call에 약하지만, 교란 후에도 주저 없이
      올바른 tool을 호출하므로 ST3 성능이 오히려 높다.

      모델                              NC정답    ST1    ST2    ST3     ST3이 최고?
      ──────────────────────────── ─────── ────── ────── ────── ────────────
      qwen3-14b                       33%   73%   76%   82%            ✓
      qwen3-32b                       33%   66%   78%   72%             
      llama-3.3-70b-instruct           0%   65%   67%   68%            ✓
      ─── 비교: 균형 모델 ───
      qwen3-next-80b-a3b-instru       83%   83%   76%   68%
      → tool 과잉 성향은 교란 내성에서 유리하나,
        no_call 정확도를 희생하는 trade-off가 존재한다.

  붕괴 순서: 인자(Arg) → 도구 선택(Tool) → 행동 판단(FC) (3/4 모델)

==============================================================================
  4. 원인 분석 — 무엇이 성능을 떨어뜨리는가?
==============================================================================

  6개 시나리오(O1/O2 × ST1/ST2/ST3)에서 '어떤 스트레스가 더 치명적인가' 비교.

  [스트레스 유형별 Performance]
    모델                             ST1(누적)   ST2(희석)   ST3(교란)       편차
    ──────────────────────────── ───────── ───────── ───────── ────────
    llama-3.3-70b-instruct          65.5%    66.8%    67.6%   2.1%p
    mistral-small-3.2-24b-ins       38.8%    20.9%    20.7%  18.1%p
    qwen3-32b                       65.5%    77.6% ◀    71.8%  12.1%p
    qwen3-14b                       72.5%    76.1%    82.3% ◀   9.8%p
    qwen3-next-80b-a3b-instru       82.6% ◀    76.1%    67.6%  15.1%p

  [콜 유형별 Tool Acc]
    모델                              O1(청약)    O2(보류)       차이
    ──────────────────────────── ───────── ───────── ────────
    llama-3.3-70b-instruct          86.2%    85.2%   1.0%p
    mistral-small-3.2-24b-ins       15.7%     0.0%  15.7%p
    qwen3-32b                       77.1%    73.1%   4.0%p
    qwen3-14b                       83.0%    85.2%   2.1%p
    qwen3-next-80b-a3b-instru       78.1%    76.3%   1.8%p

  → 가장 치명적: 조건누적(ST1) — usable 4개 모델 중 3개가 최약
    청약 vs 보류 차이: 평균 4.9%p(미미) → 변별력은 스트레스 유형(ST1/ST2/ST3)에 있음

==============================================================================
  4b. Error Taxonomy — 에러 유형 분류
==============================================================================

  각 턴의 실패를 6개 태그로 분류하여 '어떤 종류의 실수를 하는가' 진단.
  개선 방향: 각 에러 유형의 Top 태그를 우선 개선.

  태그 정의:
    WRONG_TOOL     호출해야 하는데 다른 tool 호출
    MISSED_CALL    호출해야 하는데 호출 안 함
    FALSE_CALL     호출하면 안 되는데 호출
    ARG_MISSING    tool 맞지만 필수 인자 누락
    ARG_WRONG      tool 맞지만 인자 값 틀림
    ARG_STALE      번복값 미갱신 (ST3 추정)

  ----------------------------+----------+----------+----------+----------+----------+----------+--------+
  | 모델                        |   WRONG  |  MISSED  |   FALSE  |  ARG_MIS |  ARG_WR  |   STALE  |   OK   |
  |                           |   _TOOL  |   _CALL  |   _CALL  |   SING   |    ONG   |   (ST3)  |        |
  ----------------------------+----------+----------+----------+----------+----------+----------+--------+
  | llama-3.3-70b-instruct    |    18    |     1    |    12    |     5    |    40    |    21    |    9   |
  | mistral-small-3.2-24b-ins |     2    |    84    |     0    |     0    |     3    |     0    |   17   |
  | qwen3-32b                 |    25    |     2    |     8    |     1    |    22    |    10    |   38   |
  | qwen3-14b                 |    18    |     0    |     8    |     1    |    24    |    18    |   37   |
  | qwen3-next-80b-a3b-instru |    17    |     9    |     2    |     4    |    22    |    10    |   42   |
  ----------------------------+----------+----------+----------+----------+----------+----------+--------+

  [모델별 Top 에러 + 개선 방향]
    llama-3.3-70b-instruct       ARG_WRONG(40) > ARG_STALE(21)
                                 → 인자 값 정확도 향상
    qwen3-32b                    WRONG_TOOL(25) > ARG_WRONG(22)
                                 → tool description 개선 또는 tool 선택 정확도 향상
    qwen3-14b                    ARG_WRONG(24) > WRONG_TOOL(18)
                                 → 인자 값 정확도 향상
    qwen3-next-80b-a3b-instru    ARG_WRONG(22) > WRONG_TOOL(17)
                                 → 인자 값 정확도 향상

  [1위 모델(qwen3-14b) 에러 인사이트]
    전체 106턴 중 완벽 정답 37턴 (35%)

    ● 핵심 약점 — 인자 오류 42건 (40%)
      ARG_WRONG(24) + ARG_STALE(18):
      tool은 맞게 골랐지만 인자 값을 틀림.
      특히 STALE 18건은 고객이 값을 번복한 뒤
      이전 값을 갱신하지 못한 실수 → 대화 상태 추적 실패.

    ● tool 혼동 — WRONG_TOOL 18건
      정답과 유사한 다른 tool을 호출하는 실수.

    ● No-Call 실패 — FALSE_CALL 8건
      정보 부족/범위 밖 상황에서 tool을 호출해버림.

    ● 강점 — MISSED_CALL 0건
      호출해야 할 때 빠뜨리는 일은 한 번도 없음.
      tool을 적극적으로 부르는 성향이 교란(ST3) 내성의 원인.

    한 줄 요약: 최다 에러는 ARG_WRONG(24건) → Arg Acc 개선이 최우선.

==============================================================================
  5. 모델별 판정
==============================================================================

  🏆 qwen3-14b — 권장 (실무 79%)
    + 실무 79%로 1위
    + 호출 누락 0건 — tool을 적극적으로 부름
    + NL 100%로 답변 품질 우수 → Agent+답변 겸용 가능
    - 인자 오류 42건(번복 미갱신 18건 포함) — 값을 채우는 정밀도 부족
    - tool 혼동 18건 — 유사 tool 간 구분 실패
    - No-Call 33% — 불러야/말아야 판단 부족 (tool 과잉)

     qwen3-next-80b-a3b-instru — 차선 (실무 77%)
    + No-Call 83%로 상황 판단이 정확 (균형형)
    - 인자 오류 32건(번복 미갱신 10건 포함) — 값을 채우는 정밀도 부족
    - tool 혼동 17건 — 유사 tool 간 구분 실패
    - 교란주입(ST3)에 약함 (68%, 최강 조건누적 83%과 15%p 차이)

     qwen3-32b — 조건부 사용 (실무 75%)
    + NL 83%로 답변 품질 우수 → Agent+답변 겸용 가능
    - 인자 오류 32건(번복 미갱신 10건 포함) — 값을 채우는 정밀도 부족
    - tool 혼동 25건 — 유사 tool 간 구분 실패
    - No-Call 33% — 불러야/말아야 판단 부족 (tool 과잉)
    - 조건누적(ST1)에 약함 (66%, 최강 맥락희석 78%과 12%p 차이)

     llama-3.3-70b-instruct — 비권장 (실무 68%)
    - 인자 오류 61건(번복 미갱신 21건 포함) — 값을 채우는 정밀도 부족
    - tool 혼동 18건 — 유사 tool 간 구분 실패
    - No-Call 0% — 불러야/말아야 판단 부족 (tool 과잉)
    - Tool 86% vs Arg 36% — tool은 맞추지만 인자를 절반 이상 틀림
    - 복수호출 인식 0%
    → 실무 투입 시 리스크가 높음.

  ❌ mistral-small-3.2-24b-ins — 사용 불가 (실무 26%)
    tool 호출 자체를 거의 못 함 (Tool 9%).
    No-Call 100%는 tool을 못 불러서 높은 것이지,
    판단이 좋은 게 아님.

==============================================================================
  6. 결론
==============================================================================

  [현재 위치 — qwen3-14b @T7]
    Performance 79% = Tool 88% + Arg 74% + FC 94% (tool턴) / NC 44% (no-call턴)
    tool_call 36턴 (86%) + no_call 6턴 (14%)

  [민감도 분석 — 어디를 고치면 Performance가 가장 오르는가?]
    지표               현재       여유      민감도      최대 효과     우선순위
    ──────────── ────── ──────── ──────── ────────── ────────
    Arg Acc        74%    +21%p   +2.9%p     +5.9%p      ★★★
    No-Call        44%    +41%p   +1.4%p     +5.8%p      ★★★
    Tool Acc       88%    +10%p   +2.9%p     +3.0%p       ★★
    민감도=+10%p당 Perf 변화 | 최대 효과=여유분 전부 개선 시 Perf 변화
    → Arg Acc와 No-Call이 가장 효과적인 개선 레버

  [운영 가이드]
    • 턴 제한: 실무 7턴 이내 (현재 79%, 충분히 활용 가능)
    • T7 이후 성능 하락은 스트레스 테스트 결과이며, 운영 목표 아님
    • 개선 후 이 벤치마크 재실행 → 달성 여부 확인

==============================================================================